Dataset,Test Loss,Dataset Size
2012.SMTeuroparl.test.tsv,0.2788161468502068,431
Paraphrase_Random,0.41757637341256026,249
2012.OnWN.test.tsv,0.4996130207338345,738
2012.SMTnews.test.tsv,0.5403597381930496,399
Bible,0.5559685726488294,996
Bible_Random,0.5760820219902081,997
Paralex_Random,0.5809076007892536,977
Paraphrase,0.583350832366005,449
Paralex,0.5952051866002526,755
2012.MSRpar.test.tsv,0.5966937607089572,750
Yelp_Random,0.6002956328413577,1000
2016.postediting.test.tsv,0.6043704033931793,243
2014.tweet-news.test.tsv,0.6394321833671404,750
2015.belief.test.tsv,0.6436815773558601,374
2014.deft-news.test.tsv,0.6574334680848204,300
Yelp,0.6829272700212973,1000
2014.images.test.tsv,0.7027431608854426,750
2015.answers-forums.test.tsv,0.7381210101942642,375
2016.plagiarism.test.tsv,0.7453844783262827,230
2013.FNWN.test.tsv,0.7459612520707751,189
2015.answers-students.test.tsv,0.771967678647294,750
2013.headlines.test.tsv,0.8481472417633734,750
2015.images.test.tsv,0.8537156290675284,750
2014.deft-forum.test.tsv,0.8795034185196241,439
2016.headlines.test.tsv,0.8920073298455354,249
2014.headlines.test.tsv,0.8974259572704544,750
all_dataset_loss,0.9380618500630481,24902
2015.test.tsv,0.9390036406252275,6738
2015.headlines.test.tsv,0.9639591640962044,750
2016.question-question.test.tsv,1.0830262999049236,209
2014.OnWN.test.tsv,1.0889145474986341,750
2016.answer-answer.test.tsv,1.2271598216475448,254
2013.OnWN.test.tsv,1.2687117214603818,561
