{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvsota2a52fafe8a1b4755b5f4443267bc72b3",
   "display_name": "Python 3.6.9 64-bit ('venv_sota')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import tqdm\n",
    "from scipy.stats import pearsonr as pcorr\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "# from src.features import metric_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = \"/home/shaul/workspace/GitHub/SOTA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/shaul/workspace/GitHub/SOTA\n"
    }
   ],
   "source": [
    "cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/shaul/workspace/GitHub/SOTA/data/full_DS/full_metrics.csv', index_col= 0)\n",
    "with open('/home/shaul/workspace/GitHub/SOTA/data/other/ba_all.txt','r+') as f:\n",
    "    list_ba = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need to change 'is_radical' and 'is_centrist' into one category\n",
    "# df['radical_or_centralist'] = ['radical'if row['is_radical'] ==True else \"centralist\"  if row['is_centralist'] == True else \"neither\" for index,row in df.iterrows()]\n",
    "# df.drop(columns=['is_radical','is_centralist'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_columns = ['text1','text2','label','dataset','random','duration','total_seconds','pair_id','reduced_label','annotator','radical','radical_random','radical_non_random','radical_or_centralist','num_labels','bad_annotator']\n",
    "categories = ['dataset', 'random','radical_or_centralist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([&#39;annotator&#39;, &#39;text1&#39;, &#39;text2&#39;, &#39;label&#39;, &#39;dataset&#39;, &#39;random&#39;, &#39;duration&#39;,\n       &#39;total_seconds&#39;, &#39;pair_id&#39;, &#39;reduced_label&#39;, &#39;bleu&#39;, &#39;bleu1&#39;,\n       &#39;glove_cosine&#39;, &#39;fasttext_cosine&#39;, &#39;BertScore&#39;, &#39;chrfScore&#39;,\n       &#39;POS Dist score&#39;, &#39;1-gram_overlap&#39;, &#39;ROUGE-1&#39;, &#39;ROUGE-2&#39;, &#39;ROUGE-l&#39;,\n       &#39;radical&#39;, &#39;radical_random&#39;, &#39;radical_non_random&#39;, &#39;num_labels&#39;,\n       &#39;bad_annotator&#39;, &#39;L2_score&#39;, &#39;WMD&#39;, &#39;radical_or_centralist&#39;],\n      dtype=&#39;object&#39;)"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import metric_exploration\n",
    "test = metric_exploration.Metrics_Corr(df2,non_metric_columns,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test.compare_correlations(list_ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       bleu     bleu1  glove_cosine  fasttext_cosine  BertScore  chrfScore  \\\n0  0.006192  0.036388     -0.025129        -0.038641   0.029053   0.029845   \n1 -0.017561 -0.045880      0.038510         0.041842   0.012594  -0.040251   \n\n   POS Dist score  1-gram_overlap   ROUGE-1   ROUGE-2   ROUGE-l  L2_score  \\\n0        0.002567        0.023812  0.032359  0.026236  0.036233 -0.040784   \n1       -0.008199       -0.043527 -0.040694 -0.028073 -0.031789  0.028917   \n\n        WMD  \n0 -0.027279  \n1  0.002130  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bleu</th>\n      <th>bleu1</th>\n      <th>glove_cosine</th>\n      <th>fasttext_cosine</th>\n      <th>BertScore</th>\n      <th>chrfScore</th>\n      <th>POS Dist score</th>\n      <th>1-gram_overlap</th>\n      <th>ROUGE-1</th>\n      <th>ROUGE-2</th>\n      <th>ROUGE-l</th>\n      <th>L2_score</th>\n      <th>WMD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.006192</td>\n      <td>0.036388</td>\n      <td>-0.025129</td>\n      <td>-0.038641</td>\n      <td>0.029053</td>\n      <td>0.029845</td>\n      <td>0.002567</td>\n      <td>0.023812</td>\n      <td>0.032359</td>\n      <td>0.026236</td>\n      <td>0.036233</td>\n      <td>-0.040784</td>\n      <td>-0.027279</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.017561</td>\n      <td>-0.045880</td>\n      <td>0.038510</td>\n      <td>0.041842</td>\n      <td>0.012594</td>\n      <td>-0.040251</td>\n      <td>-0.008199</td>\n      <td>-0.043527</td>\n      <td>-0.040694</td>\n      <td>-0.028073</td>\n      <td>-0.031789</td>\n      <td>0.028917</td>\n      <td>0.002130</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "example['label_by_random']"
   ]
  },
  {
   "source": [
    "### Look at the Non-Linear and Linear Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import metric_exploration\n",
    "\n",
    "test = metric_exploration.Metrics_Models(df,non_metric_columns,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_scores, fi_values = test.run_model(model_type = \"RF\")"
   ]
  }
 ]
}