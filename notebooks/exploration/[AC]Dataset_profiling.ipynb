{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Adam/PycharmProjects/SOTA\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = Path.cwd().parents[1].resolve()\n",
    "%cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PATH_ROOT,\"data/combined/with_annotators/combined_dataset.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>random</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>reduced_label</th>\n",
       "      <th>...</th>\n",
       "      <th>bleu1</th>\n",
       "      <th>glove_cosine</th>\n",
       "      <th>fasttext_cosine</th>\n",
       "      <th>BertScore</th>\n",
       "      <th>chrfScore</th>\n",
       "      <th>POS Dist score</th>\n",
       "      <th>1-gram_overlap</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3BCGN11HDM8QR</td>\n",
       "      <td>And he sent Eliakim , who was over the househo...</td>\n",
       "      <td>And he sent Eliakim , who was over the house ,...</td>\n",
       "      <td>2</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:12.000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>pair_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777466</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>1.232655</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3SQ00HYQN7FYB</td>\n",
       "      <td>And he sent Eliakim , who was over the househo...</td>\n",
       "      <td>And he sent Eliakim , who was over the house ,...</td>\n",
       "      <td>3</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:12.000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>pair_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777466</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>1.232655</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5WAWW70PYRP</td>\n",
       "      <td>And he sent Eliakim , who was over the househo...</td>\n",
       "      <td>And he sent Eliakim , who was over the house ,...</td>\n",
       "      <td>4</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:07:19.000000000</td>\n",
       "      <td>439</td>\n",
       "      <td>pair_0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777466</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>1.232655</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        annotator                                              text1  \\\n",
       "0  A3BCGN11HDM8QR  And he sent Eliakim , who was over the househo...   \n",
       "1  A3SQ00HYQN7FYB  And he sent Eliakim , who was over the househo...   \n",
       "2    A5WAWW70PYRP  And he sent Eliakim , who was over the househo...   \n",
       "\n",
       "                                               text2  label      dataset  \\\n",
       "0  And he sent Eliakim , who was over the house ,...      2  bible_human   \n",
       "1  And he sent Eliakim , who was over the house ,...      3  bible_human   \n",
       "2  And he sent Eliakim , who was over the house ,...      4  bible_human   \n",
       "\n",
       "   random                   duration  total_seconds pair_id  reduced_label  \\\n",
       "0       0  0 days 00:00:12.000000000             12  pair_0             -1   \n",
       "1       0  0 days 00:00:12.000000000             12  pair_0              0   \n",
       "2       0  0 days 00:07:19.000000000            439  pair_0              1   \n",
       "\n",
       "   ...     bleu1  glove_cosine  fasttext_cosine  BertScore  chrfScore  \\\n",
       "0  ...  0.777466      0.015252         0.035903   0.969967   0.699194   \n",
       "1  ...  0.777466      0.015252         0.035903   0.969967   0.699194   \n",
       "2  ...  0.777466      0.015252         0.035903   0.969967   0.699194   \n",
       "\n",
       "   POS Dist score  1-gram_overlap   ROUGE-1   ROUGE-2  ROUGE-l  \n",
       "0        1.232655        0.612903  0.782609  0.626866     0.75  \n",
       "1        1.232655        0.612903  0.782609  0.626866     0.75  \n",
       "2        1.232655        0.612903  0.782609  0.626866     0.75  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_ROOT / 'data' / 'raw_data' / 'with_annotators' / 'Bible_human.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'RequesterAnnotation', 'AssignmentDurationInSeconds', 'AssignmentId', 'WorkerId', 'AssignmentStatus', 'AcceptTime', 'SubmitTime', 'AutoApprovalTime', 'ApprovalTime', 'RejectionTime', 'RequesterFeedback', 'WorkTimeInSeconds', 'LifetimeApprovalRate', 'Last30DaysApprovalRate', 'Last7DaysApprovalRate', 'Input.text1', 'Input.text2', 'Answer.semantic-similarity.label', 'Approve', 'Reject']\n",
      "(3000, 25)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0120481927710845"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Input.text1', 'Input.text1']).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>HITTypeId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>RequesterAnnotation</th>\n",
       "      <th>AssignmentDurationInSeconds</th>\n",
       "      <th>AssignmentId</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>AssignmentStatus</th>\n",
       "      <th>AcceptTime</th>\n",
       "      <th>SubmitTime</th>\n",
       "      <th>AutoApprovalTime</th>\n",
       "      <th>ApprovalTime</th>\n",
       "      <th>RejectionTime</th>\n",
       "      <th>RequesterFeedback</th>\n",
       "      <th>WorkTimeInSeconds</th>\n",
       "      <th>LifetimeApprovalRate</th>\n",
       "      <th>Last30DaysApprovalRate</th>\n",
       "      <th>Last7DaysApprovalRate</th>\n",
       "      <th>Input.text1</th>\n",
       "      <th>Input.text2</th>\n",
       "      <th>Answer.semantic-similarity.label</th>\n",
       "      <th>Approve</th>\n",
       "      <th>Reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3T5ZXGO9DEODEIR3CPS5EBLJMKVQZX</td>\n",
       "      <td>3TZJMY6N8MTM6A01KQ0QESH9DVHG7U</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>meaning, semantic, similarity, text</td>\n",
       "      <td>BatchId:3851006;OriginalHitTemplateId:928390905;</td>\n",
       "      <td>14400</td>\n",
       "      <td>38SKSKU7R1XIEEK9AI1OMDFLVZJILV</td>\n",
       "      <td>A3BCGN11HDM8QR</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Wed Nov 27 08:39:22 PST 2019</td>\n",
       "      <td>Wed Nov 27 08:39:34 PST 2019</td>\n",
       "      <td>Sat Nov 30 08:39:34 PST 2019</td>\n",
       "      <td>Wed Nov 27 11:05:22 PST 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>100% (142/142)</td>\n",
       "      <td>100% (142/142)</td>\n",
       "      <td>100% (142/142)</td>\n",
       "      <td>And he sent Eliakim , who was over the household , and Shebna the scribe , and the elders of the priests , covered with sackcloth , unto Isaiah the prophet the son of Amoz .</td>\n",
       "      <td>And he sent Eliakim , who was over the house , and Shebna the scribe , and the chief priests , dressed in haircloth , to Isaiah the prophet , the son of Amoz .</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3T5ZXGO9DEODEIR3CPS5EBLJMKVQZX</td>\n",
       "      <td>3TZJMY6N8MTM6A01KQ0QESH9DVHG7U</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>meaning, semantic, similarity, text</td>\n",
       "      <td>BatchId:3851006;OriginalHitTemplateId:928390905;</td>\n",
       "      <td>14400</td>\n",
       "      <td>3SPJ0334213Y9OBEBFBESMWHHTBJYZ</td>\n",
       "      <td>A3SQ00HYQN7FYB</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Wed Nov 27 08:38:14 PST 2019</td>\n",
       "      <td>Wed Nov 27 08:38:26 PST 2019</td>\n",
       "      <td>Sat Nov 30 08:38:26 PST 2019</td>\n",
       "      <td>Wed Nov 27 11:05:23 PST 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>100% (123/123)</td>\n",
       "      <td>100% (123/123)</td>\n",
       "      <td>100% (123/123)</td>\n",
       "      <td>And he sent Eliakim , who was over the household , and Shebna the scribe , and the elders of the priests , covered with sackcloth , unto Isaiah the prophet the son of Amoz .</td>\n",
       "      <td>And he sent Eliakim , who was over the house , and Shebna the scribe , and the chief priests , dressed in haircloth , to Isaiah the prophet , the son of Amoz .</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3T5ZXGO9DEODEIR3CPS5EBLJMKVQZX</td>\n",
       "      <td>3TZJMY6N8MTM6A01KQ0QESH9DVHG7U</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>meaning, semantic, similarity, text</td>\n",
       "      <td>BatchId:3851006;OriginalHitTemplateId:928390905;</td>\n",
       "      <td>14400</td>\n",
       "      <td>3ZOTGHDK5IBFEDQ2SMBUIWP2Z2PSOD</td>\n",
       "      <td>A5WAWW70PYRP</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Wed Nov 27 08:38:38 PST 2019</td>\n",
       "      <td>Wed Nov 27 08:45:57 PST 2019</td>\n",
       "      <td>Sat Nov 30 08:45:57 PST 2019</td>\n",
       "      <td>Wed Nov 27 11:05:23 PST 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439</td>\n",
       "      <td>100% (38/38)</td>\n",
       "      <td>100% (38/38)</td>\n",
       "      <td>100% (38/38)</td>\n",
       "      <td>And he sent Eliakim , who was over the household , and Shebna the scribe , and the elders of the priests , covered with sackcloth , unto Isaiah the prophet the son of Amoz .</td>\n",
       "      <td>And he sent Eliakim , who was over the house , and Shebna the scribe , and the chief priests , dressed in haircloth , to Isaiah the prophet , the son of Amoz .</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3VDI8GSXAFT7HXW203NG7DKDHOG8GG</td>\n",
       "      <td>3TZJMY6N8MTM6A01KQ0QESH9DVHG7U</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>meaning, semantic, similarity, text</td>\n",
       "      <td>BatchId:3851006;OriginalHitTemplateId:928390905;</td>\n",
       "      <td>14400</td>\n",
       "      <td>3COPXFW7XBCZBUPV2DF7GA3ISD7KP4</td>\n",
       "      <td>AE608VRXK6M2E</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Wed Nov 27 08:35:29 PST 2019</td>\n",
       "      <td>Wed Nov 27 08:45:41 PST 2019</td>\n",
       "      <td>Sat Nov 30 08:45:41 PST 2019</td>\n",
       "      <td>Wed Nov 27 11:06:19 PST 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>100% (38/38)</td>\n",
       "      <td>100% (38/38)</td>\n",
       "      <td>100% (38/38)</td>\n",
       "      <td>And Ibneiah , the son of Jeroham , and Elah , the son of Uzzi , the son of Michri , and Meshullam , the son of Shephatiah , the son of Reuel , the son of Ibnijah ;</td>\n",
       "      <td>and Ibneiah son of Jeroham , and Elah son of Uzzi , son of Michri , and Meshullam son of Shephatiah , son of Reuel , son of Ibnijah .</td>\n",
       "      <td>5 - Highly Similar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3VDI8GSXAFT7HXW203NG7DKDHOG8GG</td>\n",
       "      <td>3TZJMY6N8MTM6A01KQ0QESH9DVHG7U</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>How similar is the meaning of these two pieces of text?</td>\n",
       "      <td>meaning, semantic, similarity, text</td>\n",
       "      <td>BatchId:3851006;OriginalHitTemplateId:928390905;</td>\n",
       "      <td>14400</td>\n",
       "      <td>3LS2AMNW5FQ31XBP0IMPNWA1HE3OQJ</td>\n",
       "      <td>A22A52DRIIEV6K</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Wed Nov 27 08:35:12 PST 2019</td>\n",
       "      <td>Wed Nov 27 08:35:31 PST 2019</td>\n",
       "      <td>Sat Nov 30 08:35:31 PST 2019</td>\n",
       "      <td>Wed Nov 27 11:06:20 PST 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>100% (1/1)</td>\n",
       "      <td>100% (1/1)</td>\n",
       "      <td>100% (1/1)</td>\n",
       "      <td>And Ibneiah , the son of Jeroham , and Elah , the son of Uzzi , the son of Michri , and Meshullam , the son of Shephatiah , the son of Reuel , the son of Ibnijah ;</td>\n",
       "      <td>and Ibneiah son of Jeroham , and Elah son of Uzzi , son of Michri , and Meshullam son of Shephatiah , son of Reuel , son of Ibnijah .</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITId                       HITTypeId  \\\n",
       "0  3T5ZXGO9DEODEIR3CPS5EBLJMKVQZX  3TZJMY6N8MTM6A01KQ0QESH9DVHG7U   \n",
       "1  3T5ZXGO9DEODEIR3CPS5EBLJMKVQZX  3TZJMY6N8MTM6A01KQ0QESH9DVHG7U   \n",
       "2  3T5ZXGO9DEODEIR3CPS5EBLJMKVQZX  3TZJMY6N8MTM6A01KQ0QESH9DVHG7U   \n",
       "3  3VDI8GSXAFT7HXW203NG7DKDHOG8GG  3TZJMY6N8MTM6A01KQ0QESH9DVHG7U   \n",
       "4  3VDI8GSXAFT7HXW203NG7DKDHOG8GG  3TZJMY6N8MTM6A01KQ0QESH9DVHG7U   \n",
       "\n",
       "                                                     Title  \\\n",
       "0  How similar is the meaning of these two pieces of text?   \n",
       "1  How similar is the meaning of these two pieces of text?   \n",
       "2  How similar is the meaning of these two pieces of text?   \n",
       "3  How similar is the meaning of these two pieces of text?   \n",
       "4  How similar is the meaning of these two pieces of text?   \n",
       "\n",
       "                                               Description  \\\n",
       "0  How similar is the meaning of these two pieces of text?   \n",
       "1  How similar is the meaning of these two pieces of text?   \n",
       "2  How similar is the meaning of these two pieces of text?   \n",
       "3  How similar is the meaning of these two pieces of text?   \n",
       "4  How similar is the meaning of these two pieces of text?   \n",
       "\n",
       "                              Keywords  \\\n",
       "0  meaning, semantic, similarity, text   \n",
       "1  meaning, semantic, similarity, text   \n",
       "2  meaning, semantic, similarity, text   \n",
       "3  meaning, semantic, similarity, text   \n",
       "4  meaning, semantic, similarity, text   \n",
       "\n",
       "                                RequesterAnnotation  \\\n",
       "0  BatchId:3851006;OriginalHitTemplateId:928390905;   \n",
       "1  BatchId:3851006;OriginalHitTemplateId:928390905;   \n",
       "2  BatchId:3851006;OriginalHitTemplateId:928390905;   \n",
       "3  BatchId:3851006;OriginalHitTemplateId:928390905;   \n",
       "4  BatchId:3851006;OriginalHitTemplateId:928390905;   \n",
       "\n",
       "   AssignmentDurationInSeconds                    AssignmentId  \\\n",
       "0                        14400  38SKSKU7R1XIEEK9AI1OMDFLVZJILV   \n",
       "1                        14400  3SPJ0334213Y9OBEBFBESMWHHTBJYZ   \n",
       "2                        14400  3ZOTGHDK5IBFEDQ2SMBUIWP2Z2PSOD   \n",
       "3                        14400  3COPXFW7XBCZBUPV2DF7GA3ISD7KP4   \n",
       "4                        14400  3LS2AMNW5FQ31XBP0IMPNWA1HE3OQJ   \n",
       "\n",
       "         WorkerId AssignmentStatus                    AcceptTime  \\\n",
       "0  A3BCGN11HDM8QR         Approved  Wed Nov 27 08:39:22 PST 2019   \n",
       "1  A3SQ00HYQN7FYB         Approved  Wed Nov 27 08:38:14 PST 2019   \n",
       "2    A5WAWW70PYRP         Approved  Wed Nov 27 08:38:38 PST 2019   \n",
       "3   AE608VRXK6M2E         Approved  Wed Nov 27 08:35:29 PST 2019   \n",
       "4  A22A52DRIIEV6K         Approved  Wed Nov 27 08:35:12 PST 2019   \n",
       "\n",
       "                     SubmitTime              AutoApprovalTime  \\\n",
       "0  Wed Nov 27 08:39:34 PST 2019  Sat Nov 30 08:39:34 PST 2019   \n",
       "1  Wed Nov 27 08:38:26 PST 2019  Sat Nov 30 08:38:26 PST 2019   \n",
       "2  Wed Nov 27 08:45:57 PST 2019  Sat Nov 30 08:45:57 PST 2019   \n",
       "3  Wed Nov 27 08:45:41 PST 2019  Sat Nov 30 08:45:41 PST 2019   \n",
       "4  Wed Nov 27 08:35:31 PST 2019  Sat Nov 30 08:35:31 PST 2019   \n",
       "\n",
       "                   ApprovalTime  RejectionTime  RequesterFeedback  \\\n",
       "0  Wed Nov 27 11:05:22 PST 2019            NaN                NaN   \n",
       "1  Wed Nov 27 11:05:23 PST 2019            NaN                NaN   \n",
       "2  Wed Nov 27 11:05:23 PST 2019            NaN                NaN   \n",
       "3  Wed Nov 27 11:06:19 PST 2019            NaN                NaN   \n",
       "4  Wed Nov 27 11:06:20 PST 2019            NaN                NaN   \n",
       "\n",
       "   WorkTimeInSeconds LifetimeApprovalRate Last30DaysApprovalRate  \\\n",
       "0                 12       100% (142/142)         100% (142/142)   \n",
       "1                 12       100% (123/123)         100% (123/123)   \n",
       "2                439         100% (38/38)           100% (38/38)   \n",
       "3                612         100% (38/38)           100% (38/38)   \n",
       "4                 19           100% (1/1)             100% (1/1)   \n",
       "\n",
       "  Last7DaysApprovalRate  \\\n",
       "0        100% (142/142)   \n",
       "1        100% (123/123)   \n",
       "2          100% (38/38)   \n",
       "3          100% (38/38)   \n",
       "4            100% (1/1)   \n",
       "\n",
       "                                                                                                                                                                     Input.text1  \\\n",
       "0  And he sent Eliakim , who was over the household , and Shebna the scribe , and the elders of the priests , covered with sackcloth , unto Isaiah the prophet the son of Amoz .   \n",
       "1  And he sent Eliakim , who was over the household , and Shebna the scribe , and the elders of the priests , covered with sackcloth , unto Isaiah the prophet the son of Amoz .   \n",
       "2  And he sent Eliakim , who was over the household , and Shebna the scribe , and the elders of the priests , covered with sackcloth , unto Isaiah the prophet the son of Amoz .   \n",
       "3            And Ibneiah , the son of Jeroham , and Elah , the son of Uzzi , the son of Michri , and Meshullam , the son of Shephatiah , the son of Reuel , the son of Ibnijah ;   \n",
       "4            And Ibneiah , the son of Jeroham , and Elah , the son of Uzzi , the son of Michri , and Meshullam , the son of Shephatiah , the son of Reuel , the son of Ibnijah ;   \n",
       "\n",
       "                                                                                                                                                       Input.text2  \\\n",
       "0  And he sent Eliakim , who was over the house , and Shebna the scribe , and the chief priests , dressed in haircloth , to Isaiah the prophet , the son of Amoz .   \n",
       "1  And he sent Eliakim , who was over the house , and Shebna the scribe , and the chief priests , dressed in haircloth , to Isaiah the prophet , the son of Amoz .   \n",
       "2  And he sent Eliakim , who was over the house , and Shebna the scribe , and the chief priests , dressed in haircloth , to Isaiah the prophet , the son of Amoz .   \n",
       "3                            and Ibneiah son of Jeroham , and Elah son of Uzzi , son of Michri , and Meshullam son of Shephatiah , son of Reuel , son of Ibnijah .   \n",
       "4                            and Ibneiah son of Jeroham , and Elah son of Uzzi , son of Michri , and Meshullam son of Shephatiah , son of Reuel , son of Ibnijah .   \n",
       "\n",
       "  Answer.semantic-similarity.label  Approve  Reject  \n",
       "0                                2      NaN     NaN  \n",
       "1                                3      NaN     NaN  \n",
       "2                                4      NaN     NaN  \n",
       "3               5 - Highly Similar      NaN     NaN  \n",
       "4                                4      NaN     NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing Outliers\n",
    "# \n",
    "# Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling, we want to currently:\n",
    "# \n",
    "# 1. Find out who the bad actors are\n",
    "# 2. See if there is any overlap from the dif. category of bad actors\n",
    "# \n",
    "# (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    "# \n",
    "# \n",
    "# The categories of bad actors are:\n",
    "# \n",
    "# [x] - Slow Annotators - ba_time </br>\n",
    "# [x] - Greater variance in random datasets than non-random datasets - ba_unvar_annotations </br>\n",
    "# [x] - Unpopular (disagree with two others often) - ba_unpopular </br>\n",
    "# [ ] - Inconsistent with sentiment != semantics - ba_semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Removing Outliers\n",
    "# \n",
    "# Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling,we want to currently:\n",
    " \n",
    " 1. Find out who the bad actors are\n",
    " 2. See if there is any overlap from the dif. category of bad actors\n",
    " \n",
    " (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    " \n",
    " \n",
    " The categories of bad actors are:\n",
    " \n",
    " [x] - Slow Annotators </br>\n",
    " [x] - Greater variance in random datasets than non-random datasets </br>\n",
    "[ ] - Unpopular (disagree with two others often) </br>\n",
    " [ ] - Inconsistent with sentiment != semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    " \n",
    "Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling,we want to currently:\n",
    " \n",
    " 1. Find out who the bad actors are\n",
    " 2. See if there is any overlap from the dif. category of bad actors\n",
    " \n",
    " (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    " \n",
    " \n",
    " The categories of bad actors are:\n",
    " \n",
    " [x] - Slow Annotators </br>\n",
    " [x] - Greater variance in random datasets than non-random datasets </br>\n",
    " [ ] - Unpopular (disagree with two others often) </br>\n",
    " [ ] - Inconsistent with sentiment != semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    " \n",
    "Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling,we want to currently:\n",
    " \n",
    " 1. Find out who the bad actors are\n",
    " 2. See if there is any overlap from the dif. category of bad actors\n",
    " \n",
    " (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    " \n",
    " \n",
    " The categories of bad actors are:\n",
    " \n",
    " [x] - Slow Annotators </br>\n",
    " [x] - Greater variance in random datasets than non-random datasets </br>\n",
    " [ ] - Unpopular (disagree with two others often) </br>\n",
    " [ ] - Inconsistent with sentiment != semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    "\n",
    "Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling, we want to currently:\n",
    "\n",
    "1. Find out who the bad actors are\n",
    "2. See if there is any overlap from the dif. category of bad actors\n",
    "\n",
    "(Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    "\n",
    "\n",
    "The categories of bad actors are:\n",
    "\n",
    "[x] - Slow Annotators </br>\n",
    "[x] - Greater variance in random datasets than non-random datasets </br>\n",
    "[ ] - Unpopular (disagree with two others often) </br>\n",
    "[ ] - Inconsistent with sentiment != semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Outliers\n",
    "\n",
    "Under the assumption that anyone that takes over the 95 percentile of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.total_seconds.describe(percentiles = [.25,.5,.75,.9,.95]))\n",
    "\n",
    "# ba = bad actor\n",
    "df['mean_annotation_time'] = df.groupby('annotator').total_seconds.transform('mean')\n",
    "print(df.mean_annotation_time.describe(percentiles = [.25,.5,.75,.9,.95]))\n",
    "ba_time = df[df.mean_annotation_time > 405].annotator.unique().tolist()\n",
    "print(len(df[df.total_seconds > 336].annotator.unique().tolist()))\n",
    "print(len(ba_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unvarianced Annotations\n",
    "Labelers whos std is too low mean non-random - random difference is too high  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelers = df[df.random==0].groupby(['annotator'])['label'].agg(['size','mean','std','min','max'])\n",
    "labelers = labelers[labelers['size']>1]\n",
    "#df = df[df.annotator.apply(lambda x:x in set(labelers.index))]\n",
    "\n",
    "labelers_rand = df[df.random==1].groupby(['annotator'])['label'].agg(['size','mean','std','min','max'])\n",
    "labelers_rand = labelers_rand[labelers_rand['size']>1]\n",
    "labelers = labelers.join(labelers_rand, rsuffix = '_rand')\n",
    "labelers['mean_random_gap'] = labelers['mean']-labelers['mean_rand']\n",
    "labelers['std_ratio'] = labelers['std']/labelers['std_rand']\n",
    "\n",
    "total_std = df.groupby('annotator')['label'].std()\n",
    "total_std.name = 'total_std'\n",
    "labelers = labelers.join(total_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_unvar_annotations = labelers[(labelers.total_std<1) & (labelers.mean_random_gap < 0)].index.tolist()\n",
    "len(ba_unvar_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpopular Annotators\n",
    "Those who over 50% of the time, disagree with the other annotators (in the reduced label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniquelabels = df.groupby(\"pair_id\")[\"reduced_label\"].nunique()\n",
    "pairs_twoagree = df_uniquelabels[(df.groupby(\"pair_id\")[\"reduced_label\"].nunique() == 2).values].index.tolist()\n",
    "df_twoagree = df[df[\"pair_id\"].isin(pairs_twoagree)]\n",
    "\n",
    "df_twoagree['generally_accepted_label'] = df_twoagree.groupby(\"pair_id\")['reduced_label'].transform('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twoagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpopularopinion = df_twoagree[df_twoagree.reduced_label != df_twoagree.generally_accepted_label].groupby('annotator').size().reset_index()\n",
    "df_unpopularopinion.columns = ['annotator','unpopular_opinion']\n",
    "\n",
    "df_allopinions = df[df['annotator'].isin(list(df_unpopularopinion.annotator))].groupby('annotator').size().reset_index()\n",
    "df_allopinions.columns = ['annotator','all_opinion']\n",
    "\n",
    "df_opinion_all_unpop = df_allopinions.merge(df_unpopularopinion,on=\"annotator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opinion_all_unpop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_unpopular = df_opinion_all_unpop[((df_opinion_all_unpop.unpopular_opinion / df_opinion_all_unpop.all_opinion) > 0.5) & (df_opinion_all_unpop.all_opinion > 4)].annotator.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment // Semantic Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis pipeline\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "text1_sent,text2_sent =[], []\n",
    "\n",
    "pbar = tqdm(total = len(df)//100+1, position = 0, leave = True)\n",
    "for i in range (len(df)//100+1):\n",
    "    t1_s = sentiment_pipe(df.text1.tolist()[100*i:np.min([100*i+100,len(df)])])\n",
    "    t2_s = sentiment_pipe(df.text2.tolist()[100*i:np.min([100*i+100,len(df)])])\n",
    "    text1_sent+=t1_s\n",
    "    text2_sent+=t2_s\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "len(text1_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = {'POSITIVE':1,'NEGATIVE':-1}\n",
    "\n",
    "df['sentiment_1'] = np.array([x['score']*sent[x['label']] for x in text1_sent]) \n",
    "df['sentiment_2'] = np.array([x['score']*sent[x['label']] for x in text2_sent])\n",
    "df['dif_sent'] =  np.abs(df['sentiment_1']-df['sentiment_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for index, row in df.iterrows():\n",
    "    first_sentence_tokens = row['text1'].strip().split()\n",
    "    second_sentence_tokens = row['text2'].strip().split()\n",
    "    pairs.append((first_sentence_tokens, second_sentence_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_bleu1 = []\n",
    "for first_sentence_tokens, second_sentence_tokens in pairs:\n",
    "\n",
    "    score_bleu1 = sentence_bleu([first_sentence_tokens], second_sentence_tokens, weights=(1, 0, 0, 0))\n",
    "    scores_bleu1.append(score_bleu1)\n",
    "\n",
    "print(np.mean(scores_bleu1))\n",
    "print(np.std(scores_bleu1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bleu_score_1'] = scores_bleu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_std_semantic = df[(df['bleu_score_1'] > 0.8) & (df['dif_sent'] > 1.9)].groupby('annotator')['label'].std().dropna()\n",
    "ba_semantics = list(annot_std_semantic[annot_std_semantic > 1.0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ba = ['ba_semantics','ba_time','ba_unpopular','ba_unvar_annotations']\n",
    "\n",
    "for a,b in list(itertools.combinations(all_ba,2)):\n",
    "    print(f\"Jaccard Similarity of {a} and {b} is :{jaccard_similarity(eval(a),eval(b))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the overlap isn't super consistent, it is interesting to note that the two most correlated groups are time and unpopularity and unpopularity with unvaried annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ba = list(set(ba_unvar_annotations + ba_unpopular + ba_time + ba_semantics))\n",
    "print(f\"Total number of bad annotators are: {len(all_ba)}\")\n",
    "print(f\"Percentage of total annotators are: {len(all_ba)/df.annotator.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the annotators so we can filter them out quicker later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ba in all_ba:\n",
    "    with open(f'data/other/{ba}.txt', 'w') as f:\n",
    "        for item in eval(ba):\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/other/ba_all.txt','w') as f:\n",
    "    for item in list(set(ba_unvar_annotations + ba_unpopular + ba_time + ba_semantics)):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOTA",
   "language": "python",
   "name": "sota"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
