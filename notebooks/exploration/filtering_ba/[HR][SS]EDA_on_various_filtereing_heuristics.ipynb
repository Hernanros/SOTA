{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvsota631bf493a94048f6adef3c5759034018",
   "display_name": "Python 3.6.9 64-bit ('venv_sota')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from sklearn.metrics import jaccard_score\n",
    "import itertools\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODULE_PATH = Path(os.getcwd()).parents[2].resolve()\n",
    "\n",
    "combined_path = \"combined_ba.pickle\"\n",
    "\n",
    "path_combined = 'combined_dataset.csv'\n",
    "path_sts = 'sts.csv'\n",
    "path_qqp = 'qqp.csv'\n",
    "path_sample_qqp = 'sample_qqp.csv'\n",
    "\n",
    "PATH_DATA = MODULE_PATH / 'data'\n",
    "PATH_COMBINED = PATH_DATA / 'datasets' / path_combined\n",
    "PATH_STS = PATH_DATA / 'datasets' / path_sts\n",
    "PATH_SAMPLE_QQP = PATH_DATA / 'datasets' / path_sample_qqp\n",
    "\n",
    "# with open(MODULE_PATH / 'data' / 'bad_annotators' / combined_path, 'rb') as f:\n",
    "#     combined_ba = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'random_honeypot',\n",
       " 'low_std',\n",
       " 'high_random',\n",
       " 'unpopular',\n",
       " 'sentiment_inconsistent']"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "filtering_heuristics = list(combined_ba.keys())[:-1]\n",
    "filtering_heuristics"
   ]
  },
  {
   "source": [
    "# EDA on the various Filtering methods\n",
    "\n",
    "What we want to explore:\n",
    "\n",
    "1) check number and percentage of unique annotators per condition, and percentage of data filtered<br>\n",
    "2) Jaccard Score of the various categories (how much overlap do they have) <br>\n",
    "3) Each individual scores impact on the inner-dataset (and intra-dataset) baseline and RF Increase <br>\n",
    "4) What combinations provide the best increase on baseline and increases <br>\n",
    "5) Sidestep filtering: removing the condition with the highest improvement, than the second highest if the improvement crosees an improvement threshold, than the 3rd, 4th etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Dataset has:\nSize:\t35912         Num Annotators:\t460         Num of unique pairs:\t11960\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_COMBINED, index_col=0)\n",
    "\n",
    "num_rows_total = df.shape[0]\n",
    "num_annotator_total = df.annotator.nunique()\n",
    "pair_id_agg = df.groupby('pair_id').size()\n",
    "pair_id_agg = pair_id_agg[pair_id_agg > 2].index\n",
    "pair_id_count_total = len(pair_id_agg)\n",
    "\n",
    "print(f\"Total Dataset has:\\nSize:\\t{num_rows_total} \\\n",
    "        Num Annotators:\\t{num_annotator_total} \\\n",
    "        Num of unique pairs:\\t{pair_id_count_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filtered Dataset on __duration__ has:\n",
      "Size:\t33768             Percentage Rows kept:\t94.03             Num Annotators:\t428             Percent Annotator Kept:\t93.04             Num of unique pairs:\t9958\n",
      "\n",
      "Filtered Dataset on __random_honeypot__ has:\n",
      "Size:\t31622             Percentage Rows kept:\t88.05             Num Annotators:\t442             Percent Annotator Kept:\t96.09             Num of unique pairs:\t8127\n",
      "\n",
      "Filtered Dataset on __low_std__ has:\n",
      "Size:\t23441             Percentage Rows kept:\t65.27             Num Annotators:\t364             Percent Annotator Kept:\t79.13             Num of unique pairs:\t3286\n",
      "\n",
      "Filtered Dataset on __high_random__ has:\n",
      "Size:\t30382             Percentage Rows kept:\t84.6             Num Annotators:\t437             Percent Annotator Kept:\t95.0             Num of unique pairs:\t7209\n",
      "\n",
      "Filtered Dataset on __unpopular__ has:\n",
      "Size:\t35901             Percentage Rows kept:\t99.97             Num Annotators:\t458             Percent Annotator Kept:\t99.57             Num of unique pairs:\t11949\n",
      "\n",
      "Filtered Dataset on __sentiment_inconsistent__ has:\n",
      "Size:\t28926             Percentage Rows kept:\t80.55             Num Annotators:\t435             Percent Annotator Kept:\t94.57             Num of unique pairs:\t6257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) check number and percentage of unique annotators per condition, and percentage of data filtered\n",
    "for key in filtering_heuristics:\n",
    "    df_filt = df[~df.annotator.isin(combined_ba[key])]\n",
    "\n",
    "    num_rows_filt = df_filt.shape[0]\n",
    "    percent_rows_kept = np.round(num_rows_filt/num_rows_total * 100,2)\n",
    "    num_annotator_filt = df_filt.annotator.nunique()\n",
    "    percent_annotator_filt = np.round(((num_annotator_filt / num_annotator_total)*100),2)\n",
    "    pair_id_agg = df_filt.groupby('pair_id').size()\n",
    "    pair_id_agg = pair_id_agg[pair_id_agg > 2].index\n",
    "    pair_id_count_filt = len(pair_id_agg)\n",
    "\n",
    "    print(f\"Filtered Dataset on __{key}__ has:\\nSize:\\t{num_rows_filt} \\\n",
    "            Percentage Rows kept:\\t{percent_rows_kept} \\\n",
    "            Num Annotators:\\t{num_annotator_filt} \\\n",
    "            Percent Annotator Kept:\\t{percent_annotator_filt} \\\n",
    "            Num of unique pairs:\\t{pair_id_count_filt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / min(len(list1),len(list2))"
   ]
  },
  {
   "source": [
    "comb2 = itertools.combinations(filtering_heuristics,2)\n",
    "for filtA, filtB in comb2:\n",
    "    jac_score = jaccard_similarity(combined_ba[filtA],combined_ba[filtB])\n",
    "    print(\"%-20s %-25s %-10s\" % (filtA,filtB, np.round(jac_score,2)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 85,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "duration             random_honeypot           0.17      \nduration             low_std                   0.22      \nduration             high_random               0.13      \nduration             unpopular                 0.0       \nduration             sentiment_inconsistent    0.12      \nrandom_honeypot      low_std                   1.0       \nrandom_honeypot      high_random               1.0       \nrandom_honeypot      unpopular                 0.0       \nrandom_honeypot      sentiment_inconsistent    0.11      \nlow_std              high_random               0.78      \nlow_std              unpopular                 0.5       \nlow_std              sentiment_inconsistent    0.08      \nhigh_random          unpopular                 0.0       \nhigh_random          sentiment_inconsistent    0.17      \nunpopular            sentiment_inconsistent    0.0       \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}