{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:36.238648Z",
     "iopub.status.busy": "2020-09-30T16:13:36.238362Z",
     "iopub.status.idle": "2020-09-30T16:13:39.585220Z",
     "shell.execute_reply": "2020-09-30T16:13:39.584564Z",
     "shell.execute_reply.started": "2020-09-30T16:13:36.238582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/PycharmProjects/SOTA/venv/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import DistilBertModel,DistilBertTokenizer\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:39.586966Z",
     "iopub.status.busy": "2020-09-30T16:13:39.586692Z",
     "iopub.status.idle": "2020-09-30T16:13:39.593132Z",
     "shell.execute_reply": "2020-09-30T16:13:39.592348Z",
     "shell.execute_reply.started": "2020-09-30T16:13:39.586939Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adam/PycharmProjects/SOTA\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = \"/Users/adam/PycharmProjects/SOTA\"\n",
    "%cd {PATH_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:39.596120Z",
     "iopub.status.busy": "2020-09-30T16:13:39.595371Z",
     "iopub.status.idle": "2020-09-30T16:13:39.845784Z",
     "shell.execute_reply": "2020-09-30T16:13:39.844732Z",
     "shell.execute_reply.started": "2020-09-30T16:13:39.596078Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PATH_ROOT,\"data/combined/with_annotators/combined_dataset.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:39.853750Z",
     "iopub.status.busy": "2020-09-30T16:13:39.852519Z",
     "iopub.status.idle": "2020-09-30T16:13:39.904576Z",
     "shell.execute_reply": "2020-09-30T16:13:39.903527Z",
     "shell.execute_reply.started": "2020-09-30T16:13:39.853705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>random</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>reduced_label</th>\n",
       "      <th>...</th>\n",
       "      <th>bleu1</th>\n",
       "      <th>glove_cosine</th>\n",
       "      <th>fasttext_cosine</th>\n",
       "      <th>BertScore</th>\n",
       "      <th>chrfScore</th>\n",
       "      <th>POS Dist score</th>\n",
       "      <th>1-gram_overlap</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3BCGN11HDM8QR</td>\n",
       "      <td>And he sent Eliakim , who was over the househo...</td>\n",
       "      <td>And he sent Eliakim , who was over the house ,...</td>\n",
       "      <td>2</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:12.000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>pair_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777466</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>1.232655</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3SQ00HYQN7FYB</td>\n",
       "      <td>And he sent Eliakim , who was over the househo...</td>\n",
       "      <td>And he sent Eliakim , who was over the house ,...</td>\n",
       "      <td>3</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:12.000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>pair_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777466</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>1.232655</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5WAWW70PYRP</td>\n",
       "      <td>And he sent Eliakim , who was over the househo...</td>\n",
       "      <td>And he sent Eliakim , who was over the house ,...</td>\n",
       "      <td>4</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:07:19.000000000</td>\n",
       "      <td>439</td>\n",
       "      <td>pair_0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777466</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>1.232655</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        annotator                                              text1  \\\n",
       "0  A3BCGN11HDM8QR  And he sent Eliakim , who was over the househo...   \n",
       "1  A3SQ00HYQN7FYB  And he sent Eliakim , who was over the househo...   \n",
       "2    A5WAWW70PYRP  And he sent Eliakim , who was over the househo...   \n",
       "\n",
       "                                               text2  label      dataset  \\\n",
       "0  And he sent Eliakim , who was over the house ,...      2  bible_human   \n",
       "1  And he sent Eliakim , who was over the house ,...      3  bible_human   \n",
       "2  And he sent Eliakim , who was over the house ,...      4  bible_human   \n",
       "\n",
       "   random                   duration  total_seconds pair_id  reduced_label  \\\n",
       "0       0  0 days 00:00:12.000000000             12  pair_0             -1   \n",
       "1       0  0 days 00:00:12.000000000             12  pair_0              0   \n",
       "2       0  0 days 00:07:19.000000000            439  pair_0              1   \n",
       "\n",
       "   ...     bleu1  glove_cosine  fasttext_cosine  BertScore  chrfScore  \\\n",
       "0  ...  0.777466      0.015252         0.035903   0.969967   0.699194   \n",
       "1  ...  0.777466      0.015252         0.035903   0.969967   0.699194   \n",
       "2  ...  0.777466      0.015252         0.035903   0.969967   0.699194   \n",
       "\n",
       "   POS Dist score  1-gram_overlap   ROUGE-1   ROUGE-2  ROUGE-l  \n",
       "0        1.232655        0.612903  0.782609  0.626866     0.75  \n",
       "1        1.232655        0.612903  0.782609  0.626866     0.75  \n",
       "2        1.232655        0.612903  0.782609  0.626866     0.75  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:40.076297Z",
     "iopub.status.busy": "2020-09-30T16:13:40.076061Z",
     "iopub.status.idle": "2020-09-30T16:13:40.079574Z",
     "shell.execute_reply": "2020-09-30T16:13:40.078691Z",
     "shell.execute_reply.started": "2020-09-30T16:13:40.076272Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Removing Outliers\n",
    "# \n",
    "# Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling, we want to currently:\n",
    "# \n",
    "# 1. Find out who the bad actors are\n",
    "# 2. See if there is any overlap from the dif. category of bad actors\n",
    "# \n",
    "# (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    "# \n",
    "# \n",
    "# The categories of bad actors are:\n",
    "# \n",
    "# [x] - Slow Annotators - ba_time </br>\n",
    "# [x] - Greater variance in random datasets than non-random datasets - ba_unvar_annotations </br>\n",
    "# [x] - Unpopular (disagree with two others often) - ba_unpopular </br>\n",
    "# [ ] - Inconsistent with sentiment != semantics - ba_semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Removing Outliers\n",
    "# \n",
    "# Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling,we want to currently:\n",
    " \n",
    " 1. Find out who the bad actors are\n",
    " 2. See if there is any overlap from the dif. category of bad actors\n",
    " \n",
    " (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    " \n",
    " \n",
    " The categories of bad actors are:\n",
    " \n",
    " [x] - Slow Annotators </br>\n",
    " [x] - Greater variance in random datasets than non-random datasets </br>\n",
    "[ ] - Unpopular (disagree with two others often) </br>\n",
    " [ ] - Inconsistent with sentiment != semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    " \n",
    "Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling,we want to currently:\n",
    " \n",
    " 1. Find out who the bad actors are\n",
    " 2. See if there is any overlap from the dif. category of bad actors\n",
    " \n",
    " (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    " \n",
    " \n",
    " The categories of bad actors are:\n",
    " \n",
    " [x] - Slow Annotators </br>\n",
    " [x] - Greater variance in random datasets than non-random datasets </br>\n",
    " [ ] - Unpopular (disagree with two others often) </br>\n",
    " [ ] - Inconsistent with sentiment != semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    " \n",
    "Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling,we want to currently:\n",
    " \n",
    " 1. Find out who the bad actors are\n",
    " 2. See if there is any overlap from the dif. category of bad actors\n",
    " \n",
    " (Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    " \n",
    " \n",
    " The categories of bad actors are:\n",
    " \n",
    " [x] - Slow Annotators </br>\n",
    " [x] - Greater variance in random datasets than non-random datasets </br>\n",
    " [ ] - Unpopular (disagree with two others often) </br>\n",
    " [ ] - Inconsistent with sentiment != semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    "\n",
    "Under the assumption that by removing some of the bad actors in the dataset, the metrics might be more reflective of the human labeling, we want to currently:\n",
    "\n",
    "1. Find out who the bad actors are\n",
    "2. See if there is any overlap from the dif. category of bad actors\n",
    "\n",
    "(Removing bad phrases should also be done - but is beyond the scope of this notebook)\n",
    "\n",
    "\n",
    "The categories of bad actors are:\n",
    "\n",
    "[x] - Slow Annotators </br>\n",
    "[x] - Greater variance in random datasets than non-random datasets </br>\n",
    "[ ] - Unpopular (disagree with two others often) </br>\n",
    "[ ] - Inconsistent with sentiment != semantics </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Outliers\n",
    "\n",
    "Under the assumption that anyone that takes over the 95 percentile of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:42.738268Z",
     "iopub.status.busy": "2020-09-30T16:13:42.735990Z",
     "iopub.status.idle": "2020-09-30T16:13:42.776296Z",
     "shell.execute_reply": "2020-09-30T16:13:42.775606Z",
     "shell.execute_reply.started": "2020-09-30T16:13:42.738218Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    39660.000000\n",
      "mean        86.010867\n",
      "std        427.060791\n",
      "min          1.000000\n",
      "25%          7.000000\n",
      "50%         12.000000\n",
      "75%         28.000000\n",
      "90%        169.000000\n",
      "95%        336.000000\n",
      "max      14079.000000\n",
      "Name: total_seconds, dtype: float64\n",
      "count    39660.000000\n",
      "mean        86.010867\n",
      "std        320.021426\n",
      "min          3.146341\n",
      "25%          9.910026\n",
      "50%         17.632653\n",
      "75%         50.928105\n",
      "90%        120.605431\n",
      "95%        405.681159\n",
      "max      13375.500000\n",
      "Name: mean_annotation_time, dtype: float64\n",
      "110\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(df.total_seconds.describe(percentiles = [.25,.5,.75,.9,.95]))\n",
    "\n",
    "# ba = bad actor\n",
    "df['mean_annotation_time'] = df.groupby('annotator').total_seconds.transform('mean')\n",
    "print(df.mean_annotation_time.describe(percentiles = [.25,.5,.75,.9,.95]))\n",
    "ba_time = df[df.mean_annotation_time > 405].annotator.unique().tolist()\n",
    "print(len(df[df.total_seconds > 336].annotator.unique().tolist()))\n",
    "print(len(ba_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unvarianced Annotations\n",
    "Labelers whos std is too low mean non-random - random difference is too high  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:44.901194Z",
     "iopub.status.busy": "2020-09-30T16:13:44.900601Z",
     "iopub.status.idle": "2020-09-30T16:13:44.940377Z",
     "shell.execute_reply": "2020-09-30T16:13:44.939234Z",
     "shell.execute_reply.started": "2020-09-30T16:13:44.901151Z"
    }
   },
   "outputs": [],
   "source": [
    "labelers = df[df.random==0].groupby(['annotator'])['label'].agg(['size','mean','std','min','max'])\n",
    "labelers = labelers[labelers['size']>1]\n",
    "#df = df[df.annotator.apply(lambda x:x in set(labelers.index))]\n",
    "\n",
    "labelers_rand = df[df.random==1].groupby(['annotator'])['label'].agg(['size','mean','std','min','max'])\n",
    "labelers_rand = labelers_rand[labelers_rand['size']>1]\n",
    "labelers = labelers.join(labelers_rand, rsuffix = '_rand')\n",
    "labelers['mean_random_gap'] = labelers['mean']-labelers['mean_rand']\n",
    "labelers['std_ratio'] = labelers['std']/labelers['std_rand']\n",
    "\n",
    "total_std = df.groupby('annotator')['label'].std()\n",
    "total_std.name = 'total_std'\n",
    "labelers = labelers.join(total_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:45.965156Z",
     "iopub.status.busy": "2020-09-30T16:13:45.964922Z",
     "iopub.status.idle": "2020-09-30T16:13:45.973967Z",
     "shell.execute_reply": "2020-09-30T16:13:45.973106Z",
     "shell.execute_reply.started": "2020-09-30T16:13:45.965132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba_unvar_annotations = labelers[(labelers.total_std<1) & (labelers.mean_random_gap < 0)].index.tolist()\n",
    "len(ba_unvar_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpopular Annotators\n",
    "Those who over 50% of the time, disagree with the other annotators (in the reduced label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:47.227782Z",
     "iopub.status.busy": "2020-09-30T16:13:47.227551Z",
     "iopub.status.idle": "2020-09-30T16:13:47.281807Z",
     "shell.execute_reply": "2020-09-30T16:13:47.280046Z",
     "shell.execute_reply.started": "2020-09-30T16:13:47.227758Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9829361a5538>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_twoagree['generally_accepted_label'] = df_twoagree.groupby(\"pair_id\")['reduced_label'].transform('median')\n"
     ]
    }
   ],
   "source": [
    "df_uniquelabels = df.groupby(\"pair_id\")[\"reduced_label\"].nunique()\n",
    "pairs_twoagree = df_uniquelabels[(df.groupby(\"pair_id\")[\"reduced_label\"].nunique() == 2).values].index.tolist()\n",
    "df_twoagree = df[df[\"pair_id\"].isin(pairs_twoagree)]\n",
    "\n",
    "df_twoagree['generally_accepted_label'] = df_twoagree.groupby(\"pair_id\")['reduced_label'].transform('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:47.989575Z",
     "iopub.status.busy": "2020-09-30T16:13:47.989268Z",
     "iopub.status.idle": "2020-09-30T16:13:48.014717Z",
     "shell.execute_reply": "2020-09-30T16:13:48.013548Z",
     "shell.execute_reply.started": "2020-09-30T16:13:47.989521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>random</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>reduced_label</th>\n",
       "      <th>...</th>\n",
       "      <th>fasttext_cosine</th>\n",
       "      <th>BertScore</th>\n",
       "      <th>chrfScore</th>\n",
       "      <th>POS Dist score</th>\n",
       "      <th>1-gram_overlap</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-l</th>\n",
       "      <th>mean_annotation_time</th>\n",
       "      <th>generally_accepted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A10DMENL2H243H</td>\n",
       "      <td>And the lord of that servant , being moved wit...</td>\n",
       "      <td>And the lord of that servant , being moved wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:12.000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>pair_2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040671</td>\n",
       "      <td>0.969194</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>1.403221</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A2G44A4ZPWRPXU</td>\n",
       "      <td>And the lord of that servant , being moved wit...</td>\n",
       "      <td>And the lord of that servant , being moved wit...</td>\n",
       "      <td>5</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:08:20.000000000</td>\n",
       "      <td>500</td>\n",
       "      <td>pair_2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040671</td>\n",
       "      <td>0.969194</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>1.403221</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1263.424242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACKF1WBCKVLY3</td>\n",
       "      <td>And the lord of that servant , being moved wit...</td>\n",
       "      <td>And the lord of that servant , being moved wit...</td>\n",
       "      <td>4</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:06.000000000</td>\n",
       "      <td>6</td>\n",
       "      <td>pair_2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040671</td>\n",
       "      <td>0.969194</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>1.403221</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>9.584450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANS8B7J9GNA2W</td>\n",
       "      <td>having become by so much better than the angel...</td>\n",
       "      <td>taking a place by so much better than the ange...</td>\n",
       "      <td>4</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:58.000000000</td>\n",
       "      <td>58</td>\n",
       "      <td>pair_5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.932658</td>\n",
       "      <td>0.682740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>3054.882353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AE7UECBR4D5E6</td>\n",
       "      <td>having become by so much better than the angel...</td>\n",
       "      <td>taking a place by so much better than the ange...</td>\n",
       "      <td>3</td>\n",
       "      <td>bible_human</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:14.000000000</td>\n",
       "      <td>14</td>\n",
       "      <td>pair_5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.932658</td>\n",
       "      <td>0.682740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>21.127424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         annotator                                              text1  \\\n",
       "6   A10DMENL2H243H  And the lord of that servant , being moved wit...   \n",
       "7   A2G44A4ZPWRPXU  And the lord of that servant , being moved wit...   \n",
       "8    ACKF1WBCKVLY3  And the lord of that servant , being moved wit...   \n",
       "15   ANS8B7J9GNA2W  having become by so much better than the angel...   \n",
       "16   AE7UECBR4D5E6  having become by so much better than the angel...   \n",
       "\n",
       "                                                text2  label      dataset  \\\n",
       "6   And the lord of that servant , being moved wit...      3  bible_human   \n",
       "7   And the lord of that servant , being moved wit...      5  bible_human   \n",
       "8   And the lord of that servant , being moved wit...      4  bible_human   \n",
       "15  taking a place by so much better than the ange...      4  bible_human   \n",
       "16  taking a place by so much better than the ange...      3  bible_human   \n",
       "\n",
       "    random                   duration  total_seconds pair_id  reduced_label  \\\n",
       "6        0  0 days 00:00:12.000000000             12  pair_2              0   \n",
       "7        0  0 days 00:08:20.000000000            500  pair_2              1   \n",
       "8        0  0 days 00:00:06.000000000              6  pair_2              1   \n",
       "15       0  0 days 00:00:58.000000000             58  pair_5              1   \n",
       "16       0  0 days 00:00:14.000000000             14  pair_5              0   \n",
       "\n",
       "    ...  fasttext_cosine  BertScore  chrfScore  POS Dist score  \\\n",
       "6   ...         0.040671   0.969194   0.607663        1.403221   \n",
       "7   ...         0.040671   0.969194   0.607663        1.403221   \n",
       "8   ...         0.040671   0.969194   0.607663        1.403221   \n",
       "15  ...         0.041350   0.932658   0.682740        0.000000   \n",
       "16  ...         0.041350   0.932658   0.682740        0.000000   \n",
       "\n",
       "    1-gram_overlap   ROUGE-1   ROUGE-2   ROUGE-l  mean_annotation_time  \\\n",
       "6         0.636364  0.790698  0.536585  0.764706             12.000000   \n",
       "7         0.636364  0.790698  0.536585  0.764706           1263.424242   \n",
       "8         0.636364  0.790698  0.536585  0.764706              9.584450   \n",
       "15        0.695652  0.800000  0.578947  0.756757           3054.882353   \n",
       "16        0.695652  0.800000  0.578947  0.756757             21.127424   \n",
       "\n",
       "    generally_accepted_label  \n",
       "6                          1  \n",
       "7                          1  \n",
       "8                          1  \n",
       "15                         1  \n",
       "16                         1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twoagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:48.411808Z",
     "iopub.status.busy": "2020-09-30T16:13:48.411576Z",
     "iopub.status.idle": "2020-09-30T16:13:48.437709Z",
     "shell.execute_reply": "2020-09-30T16:13:48.435320Z",
     "shell.execute_reply.started": "2020-09-30T16:13:48.411784Z"
    }
   },
   "outputs": [],
   "source": [
    "df_unpopularopinion = df_twoagree[df_twoagree.reduced_label != df_twoagree.generally_accepted_label].groupby('annotator').size().reset_index()\n",
    "df_unpopularopinion.columns = ['annotator','unpopular_opinion']\n",
    "\n",
    "df_allopinions = df[df['annotator'].isin(list(df_unpopularopinion.annotator))].groupby('annotator').size().reset_index()\n",
    "df_allopinions.columns = ['annotator','all_opinion']\n",
    "\n",
    "df_opinion_all_unpop = df_allopinions.merge(df_unpopularopinion,on=\"annotator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:48.876695Z",
     "iopub.status.busy": "2020-09-30T16:13:48.876419Z",
     "iopub.status.idle": "2020-09-30T16:13:48.884432Z",
     "shell.execute_reply": "2020-09-30T16:13:48.883742Z",
     "shell.execute_reply.started": "2020-09-30T16:13:48.876665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>all_opinion</th>\n",
       "      <th>unpopular_opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10DMENL2H243H</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A110SC5K5Y3IHS</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A11YCM5MVQ35YY</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A123PBQDU71I5O</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A12BPQY35PARUO</td>\n",
       "      <td>207</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        annotator  all_opinion  unpopular_opinion\n",
       "0  A10DMENL2H243H            1                  1\n",
       "1  A110SC5K5Y3IHS            5                  1\n",
       "2  A11YCM5MVQ35YY           33                  1\n",
       "3  A123PBQDU71I5O            7                  3\n",
       "4  A12BPQY35PARUO          207                 23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opinion_all_unpop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:49.196800Z",
     "iopub.status.busy": "2020-09-30T16:13:49.196560Z",
     "iopub.status.idle": "2020-09-30T16:13:49.202376Z",
     "shell.execute_reply": "2020-09-30T16:13:49.201640Z",
     "shell.execute_reply.started": "2020-09-30T16:13:49.196775Z"
    }
   },
   "outputs": [],
   "source": [
    "ba_unpopular = df_opinion_all_unpop[((df_opinion_all_unpop.unpopular_opinion / df_opinion_all_unpop.all_opinion) > 0.5) & (df_opinion_all_unpop.all_opinion > 4)].annotator.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment // Semantic Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:13:49.991322Z",
     "iopub.status.busy": "2020-09-30T16:13:49.991053Z",
     "iopub.status.idle": "2020-09-30T16:15:44.538677Z",
     "shell.execute_reply": "2020-09-30T16:15:44.537916Z",
     "shell.execute_reply.started": "2020-09-30T16:13:49.991297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34943bf27c674983a3bf1b94df6bba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=629.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e98d80861e4b2e934646522486c77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af435820e07e4990bb52c076972155a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6de228b2ae04b3f89cf15a8adf4f854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=267844284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis pipeline\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:15:59.156527Z",
     "iopub.status.busy": "2020-09-30T16:15:59.156285Z",
     "iopub.status.idle": "2020-09-30T16:39:25.800488Z",
     "shell.execute_reply": "2020-09-30T16:39:25.799737Z",
     "shell.execute_reply.started": "2020-09-30T16:15:59.156502Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [23:26<00:00,  3.54s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39660"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "text1_sent,text2_sent =[], []\n",
    "\n",
    "pbar = tqdm(total = len(df)//100+1, position = 0, leave = True)\n",
    "for i in range (len(df)//100+1):\n",
    "    t1_s = sentiment_pipe(df.text1.tolist()[100*i:np.min([100*i+100,len(df)])])\n",
    "    t2_s = sentiment_pipe(df.text2.tolist()[100*i:np.min([100*i+100,len(df)])])\n",
    "    text1_sent+=t1_s\n",
    "    text2_sent+=t2_s\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "len(text1_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = {'POSITIVE':1,'NEGATIVE':-1}\n",
    "\n",
    "df['sentiment_1'] = np.array([x['score']*sent[x['label']] for x in text1_sent]) \n",
    "df['sentiment_2'] = np.array([x['score']*sent[x['label']] for x in text2_sent])\n",
    "df['dif_sent'] =  np.abs(df['sentiment_1']-df['sentiment_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for index, row in df.iterrows():\n",
    "    first_sentence_tokens = row['text1'].strip().split()\n",
    "    second_sentence_tokens = row['text2'].strip().split()\n",
    "    pairs.append((first_sentence_tokens, second_sentence_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_bleu1 = []\n",
    "for first_sentence_tokens, second_sentence_tokens in pairs:\n",
    "\n",
    "    score_bleu1 = sentence_bleu([first_sentence_tokens], second_sentence_tokens, weights=(1, 0, 0, 0))\n",
    "    scores_bleu1.append(score_bleu1)\n",
    "\n",
    "print(np.mean(scores_bleu1))\n",
    "print(np.std(scores_bleu1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bleu_score_1'] = scores_bleu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_std_semantic = df[(df['bleu_score_1'] > 0.8) & (df['dif_sent'] > 1.9)].groupby('annotator')['label'].std().dropna()\n",
    "ba_semantics = list(annot_std_semantic[annot_std_semantic > 1.0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ba = ['ba_semantics','ba_time','ba_unpopular','ba_unvar_annotations']\n",
    "\n",
    "for a,b in list(itertools.combinations(all_ba,2)):\n",
    "    print(f\"Jaccard Similarity of {a} and {b} is :{jaccard_similarity(eval(a),eval(b))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the overlap isn't super consistent, it is interesting to note that the two most correlated groups are time and unpopularity and unpopularity with unvaried annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ba = list(set(ba_unvar_annotations + ba_unpopular + ba_time + ba_semantics))\n",
    "print(f\"Total number of bad annotators are: {len(all_ba)}\")\n",
    "print(f\"Percentage of total annotators are: {len(all_ba)/df.annotator.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the annotators so we can filter them out quicker later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ba in all_ba:\n",
    "    with open(f'data/other/{ba}.txt', 'w') as f:\n",
    "        for item in eval(ba):\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/other/ba_all.txt','w') as f:\n",
    "    for item in list(set(ba_unvar_annotations + ba_unpopular + ba_time + ba_semantics)):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOTA",
   "language": "python",
   "name": "sota"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
