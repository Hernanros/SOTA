{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvzA/onHFZKB2vVSplxhYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernanros/SOTA/blob/master/notebooks/nonlinear/%5BSS%5Dprediction%20scores%20for%20whole%20dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AM3BB0wTb0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, urllib, glob, sys\n",
        "from getpass import getpass\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB4mQSwqTeDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f0d8a719-1842-4db6-b6df-ec10af9dc477"
      },
      "source": [
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "cmd_string = \"! git clone https://{0}:{1}@github.com/Hernanros/SOTA\".format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "%cd SOTA/data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: ShaulSolomon\n",
            "Password: ··········\n",
            "/content/SOTA/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNP0q4WpTfj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/SOTA/data/combined_data_with_predictions_on_separate_datasets.csv\")"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5ARVdDT5xA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "d2de74d4-47df-4a38-80ed-c78c5fe77479"
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>label</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>bleu_allwords</th>\n",
              "      <th>bleu_withoutstop</th>\n",
              "      <th>glove_allwords</th>\n",
              "      <th>glove_withoutstop</th>\n",
              "      <th>ftext_allwords</th>\n",
              "      <th>ftext_withoutstop</th>\n",
              "      <th>WMD</th>\n",
              "      <th>1-gram_overlap</th>\n",
              "      <th>2-gram_overlap</th>\n",
              "      <th>3-gram_overlap</th>\n",
              "      <th>4-gram_overlap</th>\n",
              "      <th>ROUGE-1 recall</th>\n",
              "      <th>ROUGE-1 precision</th>\n",
              "      <th>ROUGE-1 F</th>\n",
              "      <th>ROUGE-2 recall</th>\n",
              "      <th>ROUGE-2 precision</th>\n",
              "      <th>ROUGE-2 F</th>\n",
              "      <th>ROUGE-L recall</th>\n",
              "      <th>ROUGE-L precision</th>\n",
              "      <th>ROUGE-L F</th>\n",
              "      <th>chrf_score</th>\n",
              "      <th>chrf_score_norm</th>\n",
              "      <th>POS dist score</th>\n",
              "      <th>text_1_tokens</th>\n",
              "      <th>text_2_tokens</th>\n",
              "      <th>L2_score</th>\n",
              "      <th>bert</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012.MSRpar.test.tsv</td>\n",
              "      <td>4.4</td>\n",
              "      <td>The problem likely will mean corrective change...</td>\n",
              "      <td>He said the problem needs to be corrected befo...</td>\n",
              "      <td>0.375739</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>96.2</td>\n",
              "      <td>90.82</td>\n",
              "      <td>77.23</td>\n",
              "      <td>77.39</td>\n",
              "      <td>3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.536815</td>\n",
              "      <td>2.684077</td>\n",
              "      <td>3.055075</td>\n",
              "      <td>['The', 'problem', 'likely', 'will', 'mean', '...</td>\n",
              "      <td>['He', 'said', 'the', 'problem', 'needs', 'to'...</td>\n",
              "      <td>10.527886</td>\n",
              "      <td>0.926813</td>\n",
              "      <td>2.988756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                dataset  label  ...      bert Predictions\n",
              "0  2012.MSRpar.test.tsv    4.4  ...  0.926813    2.988756\n",
              "\n",
              "[1 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upJsAJtiUCSY",
        "colab_type": "text"
      },
      "source": [
        "# Running MLP Model on the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML1VU342UGSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = df.drop(columns=[\"dataset\",\"text_1\",\"text_2\",\"text_1_tokens\",\"text_2_tokens\",\"Predictions\"])"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vz_ZhZqUXMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Put label at the end of the df\n",
        "cols = df_all.columns.to_list()\n",
        "cols.remove(\"label\")\n",
        "cols.append(\"label\")\n",
        "df_all = df_all[cols]"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYwLfe_ncbX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3ba98da-5898-46b3-f4af-0ab951fde3fb"
      },
      "source": [
        "len(df_all.columns)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9a2Nnm_UjKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DS(Dataset):\n",
        "    def __init__(self,df):\n",
        "        super().__init__()\n",
        "        X = df.iloc[:,:-1] \n",
        "        column_names = list(X.columns) \n",
        "        x = X.values #returns a numpy array\n",
        "        min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 5))\n",
        "        x_scaled = min_max_scaler.fit_transform(x)\n",
        "        self.df = np.array(pd.DataFrame(x_scaled, columns=column_names))\n",
        "        self.labels = np.array(df.iloc[:,-1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        feat = self.df[idx,:]\n",
        "        label = self.labels[idx]        \n",
        "\n",
        "        return feat,label"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fLS8se-UltF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Basemodel(nn.Module):\n",
        "  \n",
        "  def __init__(self,n_feature,n_hidden,n_output, keep_probab = 0.1):\n",
        "    '''\n",
        "    input : tensor of dimensions (batch_size*n_feature)\n",
        "    output: tensor of dimension (batchsize*1)\n",
        "    '''\n",
        "    super().__init__()\n",
        "  \n",
        "    self.input_dim = n_feature    \n",
        "    self.hidden = nn.Linear(n_feature, n_hidden) \n",
        "    self.predict = torch.nn.Linear(n_hidden, n_output)\n",
        "    self.dropout = nn.Dropout(keep_probab)\n",
        "    # self.pool = nn.MaxPool2d(2, 2)\n",
        "    # self.norm = nn.BatchNorm2d(self.num_filters)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.dropout(self.hidden(x)))\n",
        "    x = self.predict(x)\n",
        "    return x"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8i_cBtLUozZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = len(cols)-1\n",
        "num_hl = 128\n",
        "num_output = 1\n",
        "\n",
        "DATA_SIZE = df_all.shape[0]\n",
        "PERC_TRAIN = 0.8\n",
        "PERC_TEST = 1 - PERC_TRAIN\n",
        "TRAIN_SIZE = int(DATA_SIZE*PERC_TRAIN)\n",
        "TEST_SIZE = DATA_SIZE - TRAIN_SIZE\n",
        "\n",
        "model = Basemodel(num_features,num_hl,num_output)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvJiajlUUt9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(tr_loader,model,criterion,optimizer, num_epochs):\n",
        "    if torch.has_cuda:\n",
        "      device = torch.device('cuda:0')\n",
        "      model.to(device)\n",
        "    else:\n",
        "      device = torch.device('cpu:0')\n",
        "    \n",
        "    \n",
        "    training_log =[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      print(\"started training epoch no. {}\".format(epoch+1))\n",
        "      tr_loss = 0\n",
        "      for step,batch in enumerate(tr_loader):\n",
        "            feats,labels = batch\n",
        "            feats = feats.to(device,dtype=torch.float32)\n",
        "            labels = labels.to(device,dtype=torch.float32)\n",
        "            outputs = model(feats)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            tr_loss+=loss.item()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "      training_log.append({\n",
        "                'epoch':epoch,\n",
        "                'train_loss':tr_loss / len(tr_loader),\n",
        "                })\n",
        "      \n",
        "    return training_log\n",
        "  \n",
        "def test_evaluation(tst_loader,model,criterion): \n",
        "    if torch.has_cuda:\n",
        "      device = torch.device('cuda:0')\n",
        "      model.to(device)\n",
        "    else:\n",
        "      device = torch.device('cpu:0')\n",
        "     \n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "\n",
        "    for step,batch in enumerate(tst_loader):\n",
        "        feats, labels = batch\n",
        "      \n",
        "        feats = feats.to(device,dtype=torch.float32)\n",
        "        labels = labels.to(device,dtype=torch.float32)\n",
        "        outputs = model(feats)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    return test_loss / TEST_SIZE"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UFdXs8FUvsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand_list = list(range(df_all.shape[0]))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(rand_list)\n",
        "train_idx = rand_list[:int(len(rand_list)*PERC_TRAIN)]\n",
        "test_idx = rand_list[int(len(rand_list)*PERC_TEST):]"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0py9jHkqUzdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = DS(df_all.iloc[train_idx,:])\n",
        "test_set = DS(df_all.iloc[test_idx,:])\n",
        "train_loader=DataLoader(dataset= train_set, batch_size = 4, shuffle = True, num_workers = 2)\n",
        "test_loader=DataLoader(dataset= test_set, batch_size = 4, shuffle = True, num_workers = 2)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OraXdeBuUz6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "2b905a80-5b80-4cec-f2ee-c78faf7d901e"
      },
      "source": [
        "train_epoch(train_loader,model,criterion,optimizer,num_epochs= 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started training epoch no. 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "started training epoch no. 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruCoMg8JYvOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dataset_loss = test_evaluation(test_loader,model,criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbMEzDjzQoIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dataset_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR30VFS0WWiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = np.array(df_all.iloc[:,:-1])\n",
        "labels = np.array(df_all.iloc[:,-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s86cm4C6U1dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.has_cuda:\n",
        "  device = torch.device('cuda:0')\n",
        "  model.to(device)\n",
        "else:\n",
        "  device = torch.device('cpu:0')\n",
        "\n",
        "predictions = model(torch.tensor(features, dtype=torch.float32).to(device))\n",
        "predictions  = predictions.cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8aOzM-cWdow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pred = df.copy()\n",
        "df_pred['Predictions_MLP'] = pd.Series(predictions.reshape(-1))\n",
        "df_pred.to_csv(\"combined_data_with_predictions_both.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD04MjKAWw3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add ./combined_data_with_predictions_both.csv\n",
        "!git config --global user.email \"shaulsolomon@gmail.com\"\n",
        "!git config --global user.name \"Shaul Solomon\"\n",
        "!git commit -m \"Added MLP pred to whole dataset with linear pred\"\n",
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBhBDQJHW2VK",
        "colab_type": "text"
      },
      "source": [
        "# For each dataset seperately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hcx4CK7X-6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_each = df.drop(columns=[\"text_1\",\"text_2\",\"text_1_tokens\",\"text_2_tokens\",\"Predictions\"]).groupby(\"dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuAmC0zYXAnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log = {}\n",
        "all_pred = {}\n",
        "\n",
        "for name, df_group_each in df_each:\n",
        "\n",
        "  df_group = df_group_each.copy()\n",
        "  df_group.drop(columns=\"dataset\",inplace=True)\n",
        "  cols = df_group.columns.to_list()\n",
        "  cols.remove(\"label\")\n",
        "  cols.append(\"label\")\n",
        "  df_group = df_group[cols]\n",
        "\n",
        "  num_features = df_group.shape[1] - 1\n",
        "  num_hl = 128\n",
        "  num_output = 1\n",
        "\n",
        "  DATA_SIZE = df_group.shape[0]\n",
        "  PERC_TRAIN = 0.8\n",
        "  PERC_TEST = 1 - PERC_TRAIN\n",
        "  TRAIN_SIZE = int(DATA_SIZE*PERC_TRAIN)\n",
        "  TEST_SIZE = DATA_SIZE - TRAIN_SIZE\n",
        "\n",
        "  model = Basemodel(num_features,num_hl,num_output)\n",
        "  criterion = nn.L1Loss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  rand_list = list(range(df_group.shape[0]))\n",
        "  np.random.seed(42)\n",
        "  np.random.shuffle(rand_list)\n",
        "  train_idx = rand_list[:int(len(rand_list)*PERC_TRAIN)]\n",
        "  test_idx = rand_list[int(len(rand_list)*PERC_TEST):]\n",
        "  train_set = DS(df_group.iloc[train_idx,:])\n",
        "  test_set = DS(df_group.iloc[test_idx,:])\n",
        "\n",
        "  train_loader=DataLoader(dataset= train_set, batch_size = 4, shuffle = True, num_workers = 2)\n",
        "  test_loader=DataLoader(dataset= test_set, batch_size = 4, shuffle = True, num_workers = 2)\n",
        "\n",
        "  train_epoch(train_loader,model,criterion,optimizer,num_epochs= 100)\n",
        "  loss = test_evaluation(test_loader,model,criterion)\n",
        "  log[name] = loss\n",
        "\n",
        "  features = np.array(df_all.iloc[:,:-1])\n",
        "  labels = np.array(df_all.iloc[:,-1])\n",
        "\n",
        "  if torch.has_cuda:\n",
        "    device = torch.device('cuda:0')\n",
        "    model.to(device)\n",
        "  else:\n",
        "    device = torch.device('cpu:0')\n",
        "\n",
        "  predictions = model(torch.tensor(features, dtype=torch.float32).to(device))\n",
        "  predictions  = predictions.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "  all_pred[name] = pd.Series(predictions.reshape(-1))\n",
        "\n",
        "print(log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSGaTt_Jzwq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = []\n",
        "df_pred = df.copy()\n",
        "for name, group in df_pred.groupby(\"dataset\"):\n",
        "  group['Predictions_MLP'] = all_pred[name]\n",
        "  frames.append(group)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPBPl4Jp39Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_prediction_result = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrT9guiR3Iqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_prediction_result.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQBT7C7_50DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_prediction_result.to_csv('combined_data_with_predictions_on_separate_datasets_both.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vw-QuhH6QMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shouldve turned it into a variable before, but saving it now\n",
        "log['all_dataset_loss'] = all_dataset_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm-nNLCw6dhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame.from_dict(log,orient=\"index\").to_csv('test_loss_on_MLP.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXpfclYr7C5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add ./combined_data_with_predictions_on_separate_datasets_both.csv\n",
        "!git add ./test_loss_on_MLP.csv\n",
        "!git config --global user.email \"shaulsolomon@gmail.com\"\n",
        "!git config --global user.name \"Shaul Solomon\"\n",
        "!git commit -m \"Added MLP pred for all datasets\"\n",
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bShfBViL7Slf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}