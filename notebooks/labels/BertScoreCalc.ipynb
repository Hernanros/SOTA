{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "BertScoreCalc.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernanros/SOTA/blob/master/notebooks/labels/BertScoreCalc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfgonibMXYeB",
        "colab_type": "text"
      },
      "source": [
        "# BERT SCORE\n",
        "\n",
        "BERTSCORE computes the similarity\n",
        "of two sentences as a sum of cosine similarities between their tokens’ embeddings.\n",
        "\n",
        "https://arxiv.org/pdf/1904.09675.pdf\n",
        "\n",
        "Given a reference sentence x = <x1, . . . , xk> and a candidate sentence xˆ = <xˆ1, . . . , xˆl>, we use\n",
        "contextual embeddings to represent the tokens, and compute matching using cosine similarity, optionally \n",
        "weighted with inverse document frequency scores. \n",
        "\n",
        "The complete score matches each token in x to a token in xˆ to compute recall,\n",
        "and each token in xˆ to a token in x to compute precision. We use greedy matching to maximize\n",
        "the matching similarity score,2 where each token is matched to the most similar token in the other\n",
        "sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wyghfRpXYeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install bert_score==0.2.2\n",
        "# !pip install torch\n",
        "# !pip install git+https://github.com/Tiiiger/bert_score\n",
        "# !git clone https://github.com/Tiiiger/bert_score\n",
        "# %cd bert_score\n",
        "# !pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIqZxzSfXYeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -m unittest discover"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8kictmOXYeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bert_score import score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu8c6iMkXYeY",
        "colab_type": "code",
        "colab": {},
        "outputId": "e173beb3-934c-4daf-9e72-8c6fb75a1743"
      },
      "source": [
        "!wget https://sota-ydata.s3.amazonaws.com/Paraphrase.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-09 12:32:12--  https://sota-ydata.s3.amazonaws.com/Paraphrase.csv\n",
            "Resolving sota-ydata.s3.amazonaws.com (sota-ydata.s3.amazonaws.com)... 52.216.98.179\n",
            "Connecting to sota-ydata.s3.amazonaws.com (sota-ydata.s3.amazonaws.com)|52.216.98.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44220 (43K) [text/csv]\n",
            "Saving to: ‘Paraphrase.csv’\n",
            "\n",
            "Paraphrase.csv      100%[===================>]  43.18K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-06-09 12:32:12 (38.2 MB/s) - ‘Paraphrase.csv’ saved [44220/44220]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QanGX7EjXYeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"Paraphrase.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvsBUEt0XYee",
        "colab_type": "code",
        "colab": {},
        "outputId": "3590c5b9-e144-49f7-eed7-46b9052ca1d7"
      },
      "source": [
        "[df['text_2'][0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['take additional measures to']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulLmzGOOXYel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = []\n",
        "for i in range(df.shape[0]):\n",
        "  _, _, F1 = score([df['text_1'][i]], [df['text_2'][i]], lang=\"en\", verbose=True)\n",
        "  scores.append(F1.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJtsbD7FXYeq",
        "colab_type": "code",
        "colab": {},
        "outputId": "db3685c5-c575-4ac1-a726-e06f4fa01170"
      },
      "source": [
        "len(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dy3VGYvXYes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OldMin = 0.0\n",
        "OldMax = 1.0\n",
        "NewMin = 0.0\n",
        "NewMax = 5.0\n",
        "\n",
        "new_scores = []\n",
        "for score in scores:\n",
        "    new_scores.append(((score - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin) + NewMin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a66W-3qMXYev",
        "colab_type": "code",
        "colab": {},
        "outputId": "1b9d7f6b-0500-418c-f400-11ad58c50b75"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ubuntu/bert_score\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfxHWVZmXYey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(scores).to_csv(\"BERTscore_vanilla.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WufKzQuHXYe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(new_scores).to_csv(\"BERTscore_updatedrange.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}